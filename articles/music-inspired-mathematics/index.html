<!DOCTYPE html>
<html>
    <head>
        <title>chirprush - Music-Inspired Mathematics</title>

        <link rel="stylesheet" href="/assets/css/style.css">
        <link rel="stylesheet" href="/assets/css/panel.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <!-- Katex -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>

        
        <meta charset="utf-8">
    </head>

    <body>
        <div id="side-nav" class="side-panel">
            <div class="panel-content">
                <div class="panel-grid">
                    <img class="grid-pfp" src="/assets/images/pfp.svg"></img>
                    <h2 class="grid-title">Rushil Surti</h1>
                    <p class="grid-email">rush040507@gmail.com</p>
                    <div class="grid-icons"><a href="https://www.github.com/chirprush/" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.youtube.com/channel/UCSc-MTo8KGPDMLszD6jYjxA" target="_blank"><i class="fa-brands fa-youtube"></i></a> <a href="https://www.instagram.com/chirprush/" target="_blank"><i class="fa-brands fa-instagram"></i></a> <a href="https://math.stackexchange.com/users/1128617/chirpyboat73" target="_blank"><i class="fa-brands fa-stack-exchange"></i></a></div>
                </div>

                <hr class="separator" />

                <div class="description">
                    <h2>Description</h2>
                    <div class="side-line">
                        <p>An orchestra assignment special! In this article, I explore the connection between music and math concretely. In particular, we'll take a look at some signal processing and some even more out there connections to springboard into some fun pure math.</p>
                    </div>
                </div>

                <div class="contents">
                    <h2>Contents</h2>
                    <div class="side-line">
                        <ul>
                        <li><a href="#signal-processing">Signal Processing</a><ul>
                        <li><a href="#the-fourier-transform">The Fourier Transform</a></li>
                        <li><a href="#sampling-how-does-a-tuner-work">Sampling: How Does a Tuner Work?</a></li>
                        </ul></li>
                        <li><a href="#music-motivating-mathematics">Music Motivating Mathematics</a><ul>
                        <li><a href="#polyrhythms">Polyrhythms</a></li>
                        </ul></li>
                        <li><a href="#conclusion">Conclusion</a></li>
                        </ul>
                        <!--
                        <ul>
                            <li><b>Section 1.</b> Sample text</li>
                            <li><ul>
                                <li><b>Section 1.1.</b> Some stuff</li>
                            </ul></li>
                            <li><b>Section 2.</b> More sample text</li>
                        </ul>
                        -->
                    </div>
                </div>

                <div class="navigation-container">
                    <a href="/index.html">Articles</a>
                    <a href="/tags.html">Tags</a>
                    <a href="/about.html">About Me</a>
                </div>
            </div>
        </div>

        <div class="content-wrapper">
            <div class="content">
                <h1>Music-Inspired Mathematics</h1>

                <hr class="separator" />
                <div class="info-holder">
                    <span class="info-value"><b>Author:</b> Rushil Surti</span>
                    <span class="info-value"><b>Date:</b> March 21, 2025</span>
                    <span class="info-value"><b>Tags:</b>  <a href="/tags.html#fourier-transform"><span class="info-tag">fourier-transform</span></a>  <a href="/tags.html#signal-processing"><span class="info-tag">signal-processing</span></a>  <a href="/tags.html#analysis"><span class="info-tag">analysis</span></a>  <a href="/tags.html#linear-algebra"><span class="info-tag">linear-algebra</span></a> </span>
                    <span class="info-value"><b>Edited:</b> March 21, 2025</span>
                </div>

                <p>The wait is over! It's been a while since my last article was posted, but I hope with the advent of spring break and some increased motivation to learn more, I'll be outputting more articles in the near future. There's a lot I've been wanting to self-study, so perhaps I'll put down some notes!</p>
                <p>This article, although technically an assignment for an orchestra class, is something I've wanted to write for quite a while (especially after I wrote an expository paper of the same nature that didn't really live up to my expectations). The premise for writing is very simple: <em>there's quite a bit of mathematics underlying the fundamentals of sound and music!</em></p>
                <p>To a musician, this may already be apparent to some extent; we have time signatures and rhythms and harmonics and whatnot (you can even put a <a href="https://www.youtube.com/watch?v=UoDm8S7OX5s">piano on a MÃ¶bius strip</a>). However, in this article I'd like to show that even more fundamental components of music (such as sound) are formulated with even higher level mathematics, and more importantly, how a musical understanding can further mathematical thinking.</p>
                <h2 id="signal-processing">Signal Processing</h2>
                <p>The field of signal processing is one that intersects math (which deals with the theory behind analyzing them), computer science (as computers do the work to apply the theory), and some of the most important parts of modern life (these are where the signals come from!). While the field is not in any way strictly limited to analyzing only sound signals, I think it's best motivated in this domain.</p>
                <p>As one is often told, sound is the vibration of air. In particular, it's the movement of air particles in <a href="https://en.wikipedia.org/wiki/Longitudinal_wave">longitudinal waves</a> (back and forth in line with the direction of the wave). It is the frequency, the speed of the air particles as they move back and forth, that characterizes the sound we hear. The higher the frequency, or speed, the higher pitch that we hear, and the same works for the other direction. We model the behavior of the air particle mathematically by associating its position to a (periodic) function of time <span class="math inline">\(f(t)\)</span>. A very common example might be <span class="math inline">\(f(t) = A \sin(2 \pi f t)\)</span>, or in other words a periodic sine wave with amplitude <span class="math inline">\(A\)</span> and frequency <span class="math inline">\(f\)</span>.</p>
                <p>Very importantly, sound waves combine in a very natural way. If I have sound waves <span class="math inline">\(f(t)\)</span> and <span class="math inline">\(g(t)\)</span>, their combination (i.e. when the waves run into eachother in the air) is simply the wave <span class="math inline">\(h(t)\)</span>, where <span class="math inline">\(h(t) = f(t) + g(t)\)</span>. At first glance, this fact does not seem too profound, but it is the reason why the tool in the next section even works.</p>
                <p>With this background, we can now pose one of the fundamental questions of signal processing: <em>how can we break up an existing sound wave into its individual frequencies?</em> Mathematically, how can we go from <span class="math inline">\(h(t)\)</span> to <span class="math inline">\(f(t) + g(t)\)</span> as opposed to the other way around?</p>
                <p>To convince you that this is a very canonical question, I will motivate it twofold:</p>
                <ol type="1">
                <li><em>Why should we think this is possible?</em> Because our human ears can do it! Especially those with perfect pitch are able to accurately pick out correct and incorrect pitches (and thus frequencies) from arbitrary sound waves. This doesn't necessarily mean it will be a simple process, but it has to be possible!</li>
                <li><em>Why do we care?</em> There are a lot of things you can do with the individual frequencies of a sound. For a digital tuner, it is pivotal to be able to detect the individual frequencies being played. Having the individual frequencies allows one to analyze things like harmonics or overtones, and even do some really cool sound editing. In some cases, it is even more compact to store the frequencies of the sound as opposed to the sound wave data (although not sound waves precisely, this is actually the concept of JPEG images).</li>
                </ol>
                <p>Our tool of choice to decompose the waves into their frequencies is the Fourier transform.</p>
                <h3 id="the-fourier-transform">The Fourier Transform</h3>
                <p>Time to turn up the math a little! We define the Fourier transform of a signal <span class="math inline">\(f(t)\)</span> to be <span class="math inline">\(\hat f (\xi)\)</span> <span class="math display">\[
                    \hat f (\xi) = \int_{-\infty}^{\infty} f(t) e^{-2 \pi i \xi t} \, dt
                .\]</span> The formalism looks a bit scary, but the idea at hand is simple. Take a wave (the complex exponential) of known frequency <span class="math inline">\(\xi\)</span> and multiply it by our signal, <span class="math inline">\(f(t)\)</span>. If the waves match well, their product should be relatively positive at many points (because the integrand will be close to <span class="math inline">\(f(t)^2\)</span>, leading to a high contribution associated with that frequency. If the waves do not match, the contribution will be closer to <span class="math inline">\(0\)</span> or even negative. Since this transform is invertible (see the highly analogous inverse Fourier transform), we lose no information. In essence, we've transformed our viewpoint about the wave from time space to <em>frequency space</em>.</p>
                <p>Before we move on, we should make one thing clear. We didn't necessarily have to choose the complex exponential (i.e. sinusoidal waves) for a Fourier-like transform. This gets into a little bit of linear algebra. The functions that we associate to waves live in the vector space <span class="math inline">\(L^2 (\mathbf{R})\)</span>, or square-integrable functions <span class="math inline">\(f : \mathbf{R} \to \mathbf{C}\)</span> over the real line. Choosing a different set of functions as opposed to the continuum of complex exponentials amounts to choosing a different basis for this vector space of square-integrable functions. We like the complex exponentials, however, because they are easy to interpret and work with (it is easy to see what their frequency is), and they are orthonormal.</p>
                <p>The Fourier transform is ubiquitous in that it transcends application to just sound analysis or even signal processing. Later in the article, we will explore the interpretability and consequences of the Fourier transform.</p>
                <hr />
                <p><strong>Example.</strong> Let's actually try taking the Fourier transform of a function. Consider a simple decaying wave like <span class="math inline">\(f(t) = e^{-a|t|}\)</span>, where <span class="math inline">\(a\)</span> is an arbitrary decay factor. Following the definition yields <span class="math display">\[\begin{align*}
                    \hat f(\xi) &amp;= \int_{-\infty}^{\infty} e^{-a|t|-2\pi i \xi t} \, dt \\
                    &amp;= \int_{-\infty}^0 e^{(a - 2 \pi i \xi) t} \, dt + \int_{0}^{\infty}
                    e^{-(a + 2 \pi i \xi) t} \, dt \\
                    &amp;= \frac{1}{a - 2 \pi i \xi} + \frac{1}{a + 2 \pi i \xi} \\
                    &amp;= \frac{2a}{a^2 + 4 \pi^2 \xi^2}
                .\end{align*}\]</span> Looking at the graphs of <span class="math inline">\(f(t)\)</span> and <span class="math inline">\(\hat f(\xi)\)</span> side-by-side, we can realize that they are actually quite close in shape! This is very much not true in general, so it points to some interesting behavior going on with exponentials.</p>
                <p>In this case, we have a very non-sinusoidal function, so it makes sense that we'd need a continuum of different frequency sinusoidals to express it. We can observe the inverse of this behavior when one takes the Fourier transform of explicit sinusoids. This transform yields expressions involving the <a href="https://en.wikipedia.org/wiki/Dirac_delta_function">Dirac delta function</a>, which indicates not a continuum of frequencies but only a finite, discrete set of frequencies are needed.</p>
                <hr />
                <p>Before we move on, there's one problem we have to clarify: the Fourier transform gives us a frequency decomposition for the wave over <strong>all points in time</strong>. It doesn't allow us to say what frequencies are being played at any one instant in time. This is where our previous discussion on bases comes into play. Instead of having basis functions that are global across time, we can parameterize them by a value in time to be localized around. This is the general concept of <a href="https://en.wikipedia.org/wiki/Wavelet">wavelets</a>. There are many families of wavelets that each have their own perks, but the example I'll give is rather simplistic: Gaussian window wavelets. This is constructed by placing a Gaussian bell curve window centered at time <span class="math inline">\(t^*\)</span> over our original complex exponential plane wave, yielding the basis <span class="math display">\[
                    \Psi_{\xi, t^*} (t) = e^{-(t - t^*)^2 / 2 - 2 \pi i \xi t}
                .\]</span> With this, we can in theory decompose our signals now!</p>
                <h3 id="sampling-how-does-a-tuner-work">Sampling: How Does a Tuner Work?</h3>
                <p>...Except there's a catch.</p>
                <p>In real life, we cannot obtain perfectly continuous functions representing the signals we care about. To do so would require perfect information and precision, which just isn't feasible. The fact that we're stuck in the discrete world doesn't diminish the mathematical power of the Fourier transform, however. All we really need is a change of perspective.</p>
                <p>Instead of assuming the knowledge of a continuous function, we can take discrete <em>samples</em> of our wave. Mathematically, we model this as a sequence of <span class="math inline">\(N\)</span> numbers <span class="math inline">\((f_n)_{n = 1}^{N}\)</span>. Despite the discretization, many of the same properties carry over when considering signals. Most fantastically, we have discrete variants of the Fourier transform. There is the discrete Fourier transform (DFT), which is a direct analogue for the Fourier transform, and even the short-time Fourier transform (STFT), which forms an analogue for the wavelet work from earlier. In addition, there is the <a href="https://www.youtube.com/watch?v=nmgFG7PUHfo">highly celebrated</a> fast Fourier transform (FFT), which is an efficient algorithm for computing these transforms.</p>
                <p>One thing to keep in mind with these discrete variants of the Fourier transform for signal processing is the inclusion of an additional needed parameter: the sampling rate, or the number of samples that we take per second. Intuitively, low sampling rates must lose a bit of information as compared to high sampling rates. This intuition is made mathematical with the <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Nyquist-Shannon sampling theorem</a>.</p>
                <div class="black-box">
                <p><strong>Theorem (Nyquist-Shannon).</strong> A signal with sampling rate <span class="math inline">\(f_s\)</span> can only accurately describe frequencies less than or equal to <span class="math inline">\(f_s / 2\)</span>.</p>
                </div>
                <p>Thus, we have to have sufficiently enough samples. Humans can only hear in the range of roughly <span class="math inline">\(2 \text{ kHz}\)</span> to <span class="math inline">\(20 \text{ kHz}\)</span>, so one will typically see audio files with a sampling rate of around <span class="math inline">\(40 \text{ kHz}\)</span> to account for this. Sampling rate is not necessarily a measure of audio quality, but rather bandwith.</p>
                <p>The theory presented here is now sufficient for us to actually analyze signals! So, that's exactly what we're going to do. For the sake of fun and comparison, I've recorded two audio files, one where the open strings of a guitar are played and another where the open strings of a viola are played:</p>
                <audio controls src="./audio/guitar-audio.wav">
                </audio>
                <audio controls src="./audio/viola-audio.wav">
                </audio>
                <p>Let's put them through STFT! Doing so yields the following images (guitar on top, viola on bottom). Of course, some things are immediately obvious: the SFTF shows 6 main strips due to 6 strings, while the viola shows 4. In addition, we can see each of the main frequencies being carried through (these are the brighest strands), but we can also see the many overtones that characterize the instruments. Cool!</p>
                <p><img src="./images/guitar.png"></img></p>
                <p><img src="./images/viola.png"></img></p>
                <h2 id="music-motivating-mathematics">Music Motivating Mathematics</h2>
                <p>We've gone over the mathematics behind music, but we can equally go into the music behind mathematics! The Fourier transform, very naturally motivated by music theory, is almost ubiquitous in mathematics and several applied fields. It has wide applications in quantum mechanics (position and momentum among other things are Fourier transforms of each other), combinatorics (coefficient extraction allows one to derive asymptotics for the coefficients of generating functions), and even differential equations (transforming differential equations to algebraic ones).</p>
                <p>But even without all the powerful tools and fancy subfields, I'd like to argue that a musical background can offer a really cool perspective and contribute to mathematical thinking itself. This insight first jumped out to me when I was working on a Project Euler problem having nothing to do with music at all!</p>
                <p>First, let's build up with something rather music-related: polyrhythms!</p>
                <h3 id="polyrhythms">Polyrhythms</h3>
                <p>A polyrhythm is exactly what the name suggests: multiple rhythms. For our purposes, it is the superposition of several rhythms with a beat in uniform intervals. For example, a <span class="math inline">\(2, 3\)</span> polyrhythm would be a rhythm that plays twice every measure superposed over a rhythm that plays thrice every measure. We can create a polyrhythm for any arbitrary sequence of numbers.</p>
                <p>In a single measure, some of the beats of a polyrhythm may align. For example, consider the <span class="math inline">\(4, 6\)</span> polyrhythm. There's clearly an overlap when both rhythms hit the beat in the middle of the measure.</p>
                <p>A natural question might be to ask how many unique beats (i.e. considering any overlapping beats as one single beat) are heard in a single measure. For example, in a <span class="math inline">\(2, 3\)</span> polyrhythm, you can hear <span class="math inline">\(4\)</span> unique beats. In a <span class="math inline">\(2, 3, 4, 5\)</span> polyrhythm, you can hear <span class="math inline">\(10\)</span> unique beats.</p>
                <p>As mathematicians, we like to generalize, so we have the following question.</p>
                <div class="black-box">
                <p><strong>Question.</strong> For a <span class="math inline">\(q_1, q_2, \ldots, q_n\)</span> polyrhythm, how many unique beats are heard?</p>
                </div>
                <p>Depending on how simple of an answer you want, the solution isn't all too difficult. Think for a moment: we're dividing a single measure into <span class="math inline">\(q_k\)</span> parts for each <span class="math inline">\(k\)</span>. This means we can associate each beat with the time it is played, which should be of the form <span class="math inline">\(i / q_k\)</span> for some <span class="math inline">\(1 \le i \le q_k\)</span>. Thus, the number of unique beats is the number of unique fractions of these forms! This checks out with our examples from before, as with the example of the <span class="math inline">\(2, 3, 4, 5\)</span> polyrhythm, the fractions are <span class="math display">\[
                    \left\{ \frac{1}{5}, \frac{1}{4}, \frac{1}{3}, \frac{2}{5}, \frac{1}{2}, \frac{3}{5}, \frac{2}{3}, \frac{3}{4}, \frac{4}{5}, \frac{1}{1} \right\}
                .\]</span> (Although, as written, technically <span class="math inline">\(1/1\)</span> is not of the form <span class="math inline">\(i/q_k\)</span>, it looks nicer that way).</p>
                <p>Without motivation, this seems at most to be a little fun fact, but I would like the reader to consider the <a href="https://projecteuler.net/problem=228">following Project Euler problem</a> on Minkowski sums. The problem looks nothing alike to what we are doing, but hidden beneath it is some nice musical thinking!</p>
                <p>The key insight to the problem is that we only need to consider the Minkowski sum of the points on the border of the respective polygons. In addition, consider the unique point on the border of each shape when extending out a ray in the direction of an angle <span class="math inline">\(\theta\)</span> (this is always possible by convexity). The point on the border of the Minkowski sum at that same angle <span class="math inline">\(\theta\)</span> is precisely the sum of those two points. The last piece of the puzzle is that there's a vertex at angle <span class="math inline">\(\theta\)</span> in the summed shape only if there is a vertex at angle <span class="math inline">\(\theta\)</span> in any of the shapes. Of course, we can't just add up the vertices of the original shapes because we have to account for the overlaps. In effect, each vertex is a beat!</p>
                <p>But we already know how to count in situations like this! The problem reduces down to a <span class="math inline">\(1864, 1865, \ldots, 1909\)</span> polyrhythm! I'll leave the rest of the computation up to the reader.</p>
                <h2 id="conclusion">Conclusion</h2>
                <p>When I first started receiving private lessons in the viola some years ago, I told my private instructor that I liked mathematics. In response, he was delighted to tell me that there was a lot of math in music. At the time, I had no clue what he was talking about, so I unfortunately brushed him off. Years later, I am now writing an article about math in music, so I suppose he had the last laugh.</p>
                <p>Thank you for reading :D! Although some parts were inevitably rushed and scrapped, I still enjoyed writing this a lot and getting back into mathematical writing. Happy spring break, everyone!</p>
            </div>
        </div>
    </body>
</html>
